Good afternoon friends

I am going to present my paper titled "Enhancing the Performance and Reliability
of Network File System".

With this paper, we are trying to introduce a number of methods for increasing
the general performance and reducing chances of data corruption with the Network
File System.

NFS allows us to mount the partitions on a remote computer, and use them as if
they were part of the local machine.

Now, NFS is a generic term, it can refer to any network protocol which allows
accessing files on a remote disk. But today, we are talking about SUN's NFS,
which was first introduced way back in 1985.

It is still being actively developed, and is widely deployed across 
organizations, often with a directory access protocol such as LDAP.

These sytems allow people to log into their user accounts and access their files
from any machine on the network.

One such system is operational in Department of Computer Applications, College
of Engineering, Trivandrum.

The issue with NFS is, in its default configuration, it is notoriously slow.

In our lab, this means countless man hours are lost just trying to use the
computers.

Our research began in hope of finding methods to improve the performance of
the system.

NFS follows a client-server architecture. 

We began by setting up a virtual lab on our workstation with one virtual
machine running as the NFS server and the rest as clients.

At both the client and server end there are lot of options that can be tweaked.

But initially, each of the NFS instances was running in the default
configuration, as we wanted to create a base benchmark score.

For measuring the performance, a number of benchmarking tools including DBench,
Bonnie++, Phoronix Test Suite were used as no single tool could not provide
dependable measurements.

In the default configuration, NFS returned a very disappointing 0.94 MB/s

We started tweaking the settings, at the server side first, changing each
parameter, then trying combination of parameters.

Nothing seemed to improve the performance until we switched the Server side
asynchronous mode on.

The next benchmark showed us that NFS could now perform at 28.90 MB/s.

We knew that the ASYNC mode could provide a performance boost, but had not
expected it to perform this well.

When ASYNC is turned off, if the client wants to write a bumch of files, it
transfers the content of each file to the server and waits for the
acknowledgment message from the server.

The server returns the acknowledgment only after it finishes writing the data
to it's disk.

The client does not transfer the next file until it receives acknowledgment.

This is the root cause for the disappointing performance of NFS in it's
default configuration.

Turning on ASYNC means that the client receives the acknowledgment as soon as
it finishes transferring the data.

This means, the client can start sending the next file almost immediately,
considerably reducing the lag.

But if ASYNC is such a useful option, why not just leave it on? and why is it
turned off by default?

It turns out, leaving the ASYNC mode on is fairly risky.

When ASYNC is on, the clients can keep sending files to the server without
waiting for the server to write them to the disks.

It causes the server to accept more connections in unit time

But as the server cannot write the incoming data at the same rate it can accept
the data, a write queue at the server gets formed.

if the server crashes, all the data in the queue is lost.

In other words, power loss or software failure in the server can cause data
loss or corruptions in all the systems connected to the server.

But without ASYNC, we would fall back to speeds which were inadequate to say the
least.

The only way out was to propose changes to the NFS protocol.

So we came upon the idea of creating a buffer in the NFS client.

The proposed buffer would be a predefined area in the secondary memory of the
client.

All the data to be written to the server goes through the buffer.

The buffer would act like a ring buffer, deleting its oldest contents when a
certain size is reached.

The client also maintains the metadata of each file in the buffer, including
hashes for correctly identifying the files.

The files are hashed with a lighweight hash such as QUARK to reduce CPU
overhead.

Once a server crash occurs, the server requests the metadata of all the files
currently in each machine's buffer.

It then compares them with the files on the server.

If a file is missing or if the hashes do not match, the server requests the file
to be retransmitted from the client.

The client in turn retransmits the files back to the server.

This ensures that the server will always have error free copy of files.

When implemented, this mechanism can greatly reduce the chances of having
corrupt files due to asynchronous mode.

The obvious advantage of the proposed system is that, it can greatly improve the
performance of NFS without sacrificing integrity of the data.

Next, we moved to the client side of things.

Most of the parameters in the client side gave little to no performance boost,
with some negatively affecting the performance.

The only parameter which gave considerable boost in performance was the client
side asynchronous mode.

Client side async works a bit different compared to the one at the server end.

It works by using the RAM of the client machine as a huge buffer.

On a client with async enabled, when data needs to be written to the server, it
is written to the RAM.

Data is written to the server only when some conditions are met, like an
application calling the close() function or when memory is full.

This reduces the traffic between the server and client and results in better
performance among computers in the system.

This results in a speed bump of around 10 MB/s

We found that, we could further improve the read performance of a system under 
heavy load by limiting the number of simultaneous write requests accepted by the
server.

The client's behaviour will be modified such that, they try to write data to the
servers whenever possible.

The server on the other hand maintains two values, current_count and max_count,
current_count being the number of currently writing clients, and max_count the
maximum permissible number of clients.

The server accepts the write request from a client only if the number of
currently connected clients is less than maximum permissible number of clients.

If a client's request is denied, it waits for a random time before requesting
again.

The data to be written to the server stays in the RAM of the client and causes
no performance degradation.

But more importantly, it allows the server to reserve bandwidth for clients
reading data from the server, thereby ensuring performance.

These techniques, if implemented can provided a long needed performance boost to
the protocol, while also reducing chances of data corruption.

ThankYou
