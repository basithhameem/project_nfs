good afternoon friends

I am going to present my paper titled "Enhancing the Performance and Reliability
of Network File System".

With this paper, we are trying to introduce a number of methods for increasing
the general performance and reducing chances of data correction with the Network
File System.

NFS allows us to mount the partitions on a remote computer, and use them as if
they were part of the local machine.

NFS is a generic term, it can refer to any network protocol which allows
accessing files on a remote disk. But today, we are talking about SUN's NFS,
which was first introduced way back in 1985.

It is still being actively developed, and is widely deployed across 
organizations, often with a directory access protocol such as LDAP.

This allows people to log into their user accounts and access their files from
any machine on the network.

One such system is operational in Department of Computer Applications, College
of Engineering, Trivandrum.

The issue with NFS is, in its default configuration, it is notoriously slow.

In our lab, this means countless man hours are lost just trying to use the
system.

Our research began as a way to find means to improve the speed of the system

We began by setting up a virtual lab on our workstation with one virtual
machine running as the NFS server and the rest as clients.

Each of the NFS instances was running in the default configuration, as we
wanted to create a base benchmark score.

Now, NFS has a client-server architecture and at both the client and server end
there are lot of options that can be tweaked.

For measuring the performance, a number of benchmarking tools including DBench,
Bonnie++, Phoronix Test Suite were used as no single tool could not provide
dependable measurements.

In the default configuration, NFS returned a very disappointing 0.94 MB/s

We started tweaking the settings, at the server side first, changing each
parameter, then trying combination of parameters.

Nothing seemed to improve the performance until we switched the Server side
asynchronous mode on.

The next benchmark showed us that NFS could now perform at 28.90 MB/s.

We knew that the ASYNC mode could provide a performance boost, but had not
expected it to perform this well.

When ASYNC is turned off and the client wants to write a bumch of files, it
transfers the content of each file to the server and waits for the
acknowledgment message from the server.

The server returns the acknowledgment only after it finishes writing the data
completely.

The client does not transfer the next file until it receives acknowledgment.

This is the root cause for the disappointing performance of NFS in it's
default configuration.

Turning on ASYNC means that the client receives the acknowledgment as soon as
it finishes transferring the data, speeding things up considerably.

But if ASYNC is such a useful option, why is turned off by default?

It turns out, leaving the ASYNC mode on is fairly risky.

It causes the NFS server to accept more connections in unit time and the write
queue at the server side starts filling up.

if the server crashes, all the data from the queue is lost.

But when ASYNC is turned off, no amount of fiddling in the server or client
part could improve the performance of the system.

We saw that, the only way out was to modify the NFS protocol.

So we came upon the idea of creating a buffer in the NFS client.

The buffer would be a predefined area in the secondary memory of the client.

When the client tries to write some data to the server, a copy of it is stored
in the buffer.

When the buffer reaches the a predefined size, the oldest files are deleted.

The client also maintains a metadata file in the buffer containing hashes of
each file.

The files are hashed with a lighweight hash such as QUARK to reduce CPU
overhead.

When a server crash occurs, the server requests the metadata file, and then
compares it with the hashes of recently modified files.

The server creates a list of missing or corrupt files, which is then sent to
the client.

The client in turn retransmits the files back to the server.

When implemented, this mechanism can greatly reduce the chances of having
corrupt files due to asynchronous mode.

In the client side, it was almost the same story. The only parameter which
provided a boost was the client side asynchronous mode.

The client side asynchronous mode works by using the RAM of the client machine
as a huge buffer.

Data is written to the server only when some conditions are met, like an
application calling the close() function or when sync is called.

This reduces the traffic between the server and client and results in better
performance among computers in the system.

We found that we might be able to optimize the traffic in the system by
forcing the client to write data to server when the size of data reaches a user
set threshold and at the server side, controlling how many clients can write
at the same time.

The motive is to reduce the idle time of the server while also ensuring
sufficient bandwidth is available for clients who wishes to read data from the
server
